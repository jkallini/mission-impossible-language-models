{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    CHECKPOINT_PATH,\n",
    "    BABYLM_DATA_PATH,\n",
    "    gpt2_original_tokenizer,\n",
    "    gpt2_hop_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modeling_gpt2 import GPT2Model\n",
    "from tree_projection import TreeProjection\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"control_agreement_geom_attn\"\n",
    "random_seed = 53\n",
    "perturbation_type = \"shuffle_nondeterministic\"\n",
    "train_set = \"100M\"\n",
    "ckpt = 3000\n",
    "EOS_TOKEN = gpt2_original_tokenizer.eos_token_id\n",
    "\n",
    "FILE_SAMPLE_SIZE = 1000\n",
    "MAX_SEQ_LEN = 1024\n",
    "\n",
    "# Get path to model\n",
    "model = f\"{run_name}_seed{random_seed}\"\n",
    "model_path = f\"{CHECKPOINT_PATH}/{perturbation_type}_{train_set}/{model}/checkpoints/checkpoint-\"\n",
    "\n",
    "model_path = \"/nlp/scr3/nlp/llms-in-llms/babylm_models/babylm_shuffle_nondeterministic_100M_randinit/babylm_shuffle_nondeterministic_100M_randinit_seed53/runs/babylm_shuffle_nondeterministic_100M_randinit_seed53/checkpoint-\"\n",
    "model = GPT2Model.from_pretrained(model_path + str(ckpt)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = sorted(glob(BABYLM_DATA_PATH +\n",
    "    \"/babylm_data_perturbed/babylm_{}/babylm_test_affected/*\".format(perturbation_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/aochildes_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/bnc_spoken_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/cbt_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/children_stories_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/gutenberg_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/open_subtitles_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/qed_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/simple_wikipedia_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/switchboard_affected.test\n",
      "/nlp/scr3/nlp/llms-in-llms/mission-impossible/babylm_data/babylm_data_perturbed/babylm_shuffle_nondeterministic/babylm_test_affected/wikipedia_affected.test\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(random_seed)\n",
    "\n",
    "samples = []\n",
    "for test_file in test_files:\n",
    "    print(test_file)\n",
    "\n",
    "    # Get tokens from test file (+ eos token), and subsample\n",
    "    f = open(test_file, 'r')\n",
    "    file_token_sequences = [\n",
    "        [int(s) for s in l.split()] + [EOS_TOKEN] for l in f.readlines()]\n",
    "    file_token_sequences = [\n",
    "        toks for toks in file_token_sequences if len(toks) < MAX_SEQ_LEN]\n",
    "    sample_indices = rng.choice(\n",
    "        list(range(len(file_token_sequences))), FILE_SAMPLE_SIZE, replace=False)\n",
    "    file_token_sequences = [file_token_sequences[i]\n",
    "                            for i in sample_indices]\n",
    "    samples.extend(file_token_sequences)\n",
    "\n",
    "# Shuffle samples\n",
    "shuffle(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Tree Metric: 100%|██████████| 1000/1000 [05:56<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Metric: 0.11925368756055832±0.11543823033571243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tree_projector = TreeProjection(model=model)\n",
    "\n",
    "all_scores = []\n",
    "for input_ids in tqdm(samples[:1000], desc=\"Computing Tree Metric\"):\n",
    "            \n",
    "    sci_chart = tree_projector.compute_sci_chart(\n",
    "        input_ids,\n",
    "        [1] * len(input_ids),  # all tokens are visible\n",
    "        st_threshold=4,\n",
    "        layer_id=11\n",
    "    )\n",
    "\n",
    "    _, score = tree_projector(\n",
    "        sci_chart=sci_chart,\n",
    "        input_ids=input_ids,\n",
    "        projection_algorithm=\"dp\"\n",
    "    )\n",
    "\n",
    "    all_scores.append(score)\n",
    "\n",
    "mean_value = np.mean(all_scores)\n",
    "std_dev_value = np.std(all_scores)\n",
    "\n",
    "print(f\"Tree Metric: {mean_value}±{std_dev_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mission-impossible-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
